{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"Datasets/train.txt\",names=['Message','label'],sep=\";\")\n",
    "test_data = pd.read_csv(\"Datasets/test.txt\",names=['Message','label'],sep=\";\")\n",
    "val_data = pd.read_csv(\"Datasets/val.txt\",names=['Message','label'],sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'fear', 'joy', 'love', 'sadness', 'surprise']\n",
      "['anger', 'fear', 'joy', 'love', 'sadness', 'surprise']\n",
      "['anger', 'fear', 'joy', 'love', 'sadness', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(train_data['label'].unique()))\n",
    "print(sorted(test_data['label'].unique()))\n",
    "print(sorted(val_data['label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb = LabelEncoder()\n",
    "lb.fit(sorted(train_data['label'].unique()))\n",
    "lb.transform(sorted(train_data['label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_label(column):\n",
    "    lb = LabelEncoder()\n",
    "    return lb.fit_transform(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>label</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message    label  labels\n",
       "0                            i didnt feel humiliated  sadness       4\n",
       "1  i can go from feeling so hopeless to so damned...  sadness       4\n",
       "2   im grabbing a minute to post i feel greedy wrong    anger       0\n",
       "3  i am ever feeling nostalgic about the fireplac...     love       3\n",
       "4                               i am feeling grouchy    anger       0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['labels'] = to_label(train_data['label'])\n",
    "test_data['labels'] = to_label(test_data['label'])\n",
    "val_data['labels'] = to_label(val_data['label'])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
    "                           text)\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
    "            ' '.join(emoticons).replace('-', ''))\n",
    "    return text\n",
    "\n",
    "train_data['Message'] = train_data['Message'].apply(preprocessor)\n",
    "test_data['Message'] = test_data['Message'].apply(preprocessor)\n",
    "val_data['Message'] = val_data['Message'].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def tokenizer(text):\n",
    "    return text.split()\n",
    "\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\infra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data['Message'].values\n",
    "y_train = train_data['labels'].values\n",
    "\n",
    "X_test = test_data['Message'].values\n",
    "y_test = test_data['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        TfidfVectorizer(lowercase=False)),\n",
       "                                       ('clf',\n",
       "                                        LogisticRegression(random_state=1,\n",
       "                                                           solver='liblinear'))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'clf__C': [1.0, 10.0, 100.0],\n",
       "                          'clf__penalty': ['l1', 'l2'],\n",
       "                          'vect__ngram_range': [(1, 1)],\n",
       "                          'vect__stop_words': [['i', 'me', 'my', 'myself', 'we',\n",
       "                                                'our', 'ours', 'ourselves',\n",
       "                                                'you', \"you're\", \"you've...\n",
       "                                                'our', 'ours', 'ourselves',\n",
       "                                                'you', \"you're\", \"you've\",\n",
       "                                                \"you'll\", \"you'd\", 'your',\n",
       "                                                'yours', 'yourself',\n",
       "                                                'yourselves', 'he', 'him',\n",
       "                                                'his', 'himself', 'she',\n",
       "                                                \"she's\", 'her', 'hers',\n",
       "                                                'herself', 'it', \"it's\", 'its',\n",
       "                                                'itself', ...],\n",
       "                                               None],\n",
       "                          'vect__tokenizer': [<function tokenizer at 0x000001732F528430>,\n",
       "                                              <function tokenizer_porter at 0x000001732F528160>],\n",
       "                          'vect__use_idf': [False]}],\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents = None,\n",
    "                       lowercase=False,\n",
    "                       preprocessor=None)\n",
    "lr = LogisticRegression(solver=\"liblinear\",random_state=1)\n",
    "param_grid = [{\"vect__ngram_range\":[(1,1)],\n",
    "              \"vect__stop_words\":[stop,None],\n",
    "              \"clf__penalty\":[\"l1\",\"l2\"],\n",
    "              \"vect__tokenizer\":[tokenizer,tokenizer_porter],\n",
    "              \"clf__C\":[1.0,10.0,100.0]},\n",
    "             {'vect__ngram_range': [(1, 1)],\n",
    "               'vect__stop_words': [stop, None],\n",
    "               'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
    "               'vect__use_idf':[False],\n",
    "               'vect__norm':[None],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [1.0, 10.0, 100.0]}]\n",
    "pipe = Pipeline([(\"vect\",tfidf),\n",
    "                (\"clf\",lr)])\n",
    "grid = GridSearchCV(pipe,param_grid,scoring=\"accuracy\",cv=5,verbose=2,n_jobs=-1)\n",
    "grid.fit(X_train,y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90       274\n",
      "           1       0.87      0.88      0.87       222\n",
      "           2       0.92      0.92      0.92       697\n",
      "           3       0.80      0.78      0.79       163\n",
      "           4       0.94      0.95      0.94       577\n",
      "           5       0.68      0.67      0.68        67\n",
      "\n",
      "    accuracy                           0.90      2000\n",
      "   macro avg       0.85      0.85      0.85      2000\n",
      "weighted avg       0.90      0.90      0.90      2000\n",
      "\n",
      "accuracy: 0.901\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "prediction = grid.predict(X_test)\n",
    "print(classification_report(prediction,y_test))\n",
    "print(\"accuracy: {}\".format(accuracy_score(prediction,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90       271\n",
      "           1       0.86      0.89      0.87       215\n",
      "           2       0.93      0.90      0.91       716\n",
      "           3       0.79      0.77      0.78       163\n",
      "           4       0.94      0.95      0.94       577\n",
      "           5       0.65      0.74      0.69        58\n",
      "\n",
      "    accuracy                           0.90      2000\n",
      "   macro avg       0.84      0.86      0.85      2000\n",
      "weighted avg       0.90      0.90      0.90      2000\n",
      "\n",
      "accuracy: 0.8985\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1,1),\n",
    "                       stop_words=grid.best_params_['vect__stop_words'],\n",
    "                       tokenizer=tokenizer,\n",
    "                       lowercase=False,\n",
    "                       strip_accents=None,\n",
    "                       preprocessor=None,\n",
    "                       use_idf=False)\n",
    "lr = LogisticRegression(penalty=\"l1\",random_state=1,solver=\"liblinear\",\n",
    "                       C=1.0)\n",
    "\n",
    "pipeline = Pipeline([(\"vect\",tfidf),\n",
    "                    (\"clf\",lr)])\n",
    "pipeline.fit(X_train,y_train.ravel())\n",
    "prediction = pipeline.predict(X_test)\n",
    "print(classification_report(prediction,y_test))\n",
    "print(\"accuracy: {}\".format(accuracy_score(prediction,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(text):\n",
    "    predicted_value = grid.predict(text)\n",
    "    value = lb.inverse_transform([predicted_value])\n",
    "    print(\"the message: \",text)\n",
    "    return value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger' 'fear' 'joy' 'love' 'sadness' 'surprise']\n"
     ]
    }
   ],
   "source": [
    "print(lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the message:  ['im feeling quite sad and sorry for myself but ill snap out of it soon']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sadness'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred([val_data['Message'][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the message:  ['i feel like a faithful servant']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'joy'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred([val_data['Message'][2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the message:  ['i am just feeling cranky and blue']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'anger'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred([val_data['Message'][3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the message:  ['i see wonderful godly parents taking care of their childrens i praise god even though i feel jealous']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\infra\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'anger'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred([val_data['Message'][np.random.randint(low=0,high=700)]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
